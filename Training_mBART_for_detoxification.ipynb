{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training mBART for detoxification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Train mBART for RUSSE Detox 2022"
      ],
      "metadata": {
        "id": "2RM65GlRzZGe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proprocess data"
      ],
      "metadata": {
        "id": "ffX1Z-0EdKAl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7smUZzudGeq",
        "outputId": "d677aaae-e156-4579-aed6-28a5ef8de66b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'russe_detox_2022'...\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 82 (delta 22), reused 43 (delta 16), pack-reused 29\u001b[K\n",
            "Unpacking objects: 100% (82/82), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/skoltech-nlp/russe_detox_2022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "cd805391-4746-43ac-f041-e76ce4597633",
        "id": "Ja_qsX8U1fad"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11981</th>\n",
              "      <td>и вот какая скотина это постит? какие лайки? г...</td>\n",
              "      <td>и вот какой плохой человепк это постит? какие ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1853</th>\n",
              "      <td>ебнутая!!!! выкинул бы её и все дела!!!!</td>\n",
              "      <td>выкинул бы её и все дела!!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3818</th>\n",
              "      <td>можешь не говорить какое, это пердёж таких как...</td>\n",
              "      <td>можешь не говорить какое, это неправда</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3417</th>\n",
              "      <td>а где папаша????? и зачем от таких уродов рожа...</td>\n",
              "      <td>а где папаша????? и зачем от таких людей рожат...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>665</th>\n",
              "      <td>так всех Элиенс лишитесь,неблагодарные говнюки(</td>\n",
              "      <td>так всех Элиенс лишитесь,неблагодарные люди(</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>блять! так вот кто разбрасывает коронавирус!:-...</td>\n",
              "      <td>Так вот кто разбрасывает коронавирус!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3347</th>\n",
              "      <td>валить таких мразей сразу с порога!!!!!!!</td>\n",
              "      <td>Наказывать таких сразу с порога</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9988</th>\n",
              "      <td>Пидоры, а я так надеелся, что меня дропнут(</td>\n",
              "      <td>а я так надеелся, что меня дропнут(</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7242</th>\n",
              "      <td>мышка пидараска глючит,невозможно играть!(((</td>\n",
              "      <td>Мышка не работает, невозмодно игратт</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7667</th>\n",
              "      <td>сейчас эту мразь будем содержать. они не работ...</td>\n",
              "      <td>Сейчас этого человека будем содержать. Они не ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   input  \\\n",
              "11981  и вот какая скотина это постит? какие лайки? г...   \n",
              "1853            ебнутая!!!! выкинул бы её и все дела!!!!   \n",
              "3818   можешь не говорить какое, это пердёж таких как...   \n",
              "3417   а где папаша????? и зачем от таких уродов рожа...   \n",
              "665      так всех Элиенс лишитесь,неблагодарные говнюки(   \n",
              "204    блять! так вот кто разбрасывает коронавирус!:-...   \n",
              "3347           валить таких мразей сразу с порога!!!!!!!   \n",
              "9988         Пидоры, а я так надеелся, что меня дропнут(   \n",
              "7242        мышка пидараска глючит,невозможно играть!(((   \n",
              "7667   сейчас эту мразь будем содержать. они не работ...   \n",
              "\n",
              "                                                  target  \n",
              "11981  и вот какой плохой человепк это постит? какие ...  \n",
              "1853                        выкинул бы её и все дела!!!!  \n",
              "3818              можешь не говорить какое, это неправда  \n",
              "3417   а где папаша????? и зачем от таких людей рожат...  \n",
              "665         так всех Элиенс лишитесь,неблагодарные люди(  \n",
              "204                Так вот кто разбрасывает коронавирус!  \n",
              "3347                     Наказывать таких сразу с порога  \n",
              "9988                 а я так надеелся, что меня дропнут(  \n",
              "7242                Мышка не работает, невозмодно игратт  \n",
              "7667   Сейчас этого человека будем содержать. Они не ...  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# пока что мы объединяем dev и train: не хотим валидироваться на обучении, раз существует test-сет\n",
        "data_df = pd.concat([\n",
        "           pd.read_csv(\"./russe_detox_2022/data/input/dev.tsv\", sep=\"\\t\"),\n",
        "           pd.read_csv(\"./russe_detox_2022/data/input/train.tsv\", sep=\"\\t\").drop([\"index\"], axis=1)\n",
        "], axis=0).reset_index(drop=True)\n",
        "\n",
        "# если у фразы несколько вариантов исправления — просто кладём их все как пары input-target\n",
        "# исходим из того, что наши модели достаточно complex, чтобы это их не запутало\n",
        "train_dict = {\n",
        "    \"input\": [],\n",
        "    \"target\": []\n",
        "}\n",
        "\n",
        "for tc, nc1, nc2, nc3 in zip(list(data_df[\"toxic_comment\"]), list(data_df[\"neutral_comment1\"]),\n",
        "                             list(data_df[\"neutral_comment2\"]), list(data_df[\"neutral_comment3\"])):\n",
        "  # здесь немножко препроцесса: из-за особенностей sentencepiece-токенизации модели плохо понимают\n",
        "  # текст, написанный КАПСОМ. мы будем смотреть, если во входной строке больше 50% символов — капс,\n",
        "  # и в таком случае приводить её к нижнему регистру\n",
        "  input_str = str(tc)\n",
        "  if len([c for c in input_str if re.search(r\"[A-ZА-ЯЁ]\", c)]) / len(input_str) > 0.5:\n",
        "    input_str = input_str.lower()\n",
        "\n",
        "  train_dict[\"input\"].append(input_str)\n",
        "  train_dict[\"target\"].append(str(nc1))\n",
        "  if type(nc2) != float: # проверка на NaN\n",
        "    train_dict[\"input\"].append(input_str)\n",
        "    train_dict[\"target\"].append(str(nc2))\n",
        "  if type(nc3) != float: # проверка на NaN\n",
        "    train_dict[\"input\"].append(input_str)\n",
        "    train_dict[\"target\"].append(str(nc3))\n",
        "\n",
        "train_df = pd.DataFrame(train_dict)\n",
        "\n",
        "# перемешиваем датасет; задаём seed, чтобы результаты перемешивания совпадали между разными запусками\n",
        "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# и всё, этого достаточно! токенизаторы у каждой модели свои, лемматизация и другая нормализация\n",
        "# только уменьшат количество полезных данных для transformer-нейросетей\n",
        "\n",
        "# пример того, что у нас в датафрейме:\n",
        "train_df.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train mBART (FB)"
      ],
      "metadata": {
        "id": "zn0M-MPAzR00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# устанавливаем необходимые библиотеки\n",
        "!pip install -qqq happytransformer sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONu1k_Y-zbOF",
        "outputId": "1e9f0fbd-22f1-4446-e9cf-2b79d1ae72ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 45 kB 2.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 17.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 325 kB 50.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 42.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 45.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 52.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 134 kB 57.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 50.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 61.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 62.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 58.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 54.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 75.0 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# подготавливаем обучающие данные\n",
        "train_df.to_csv(\"train.csv\", index=False, quoting=csv.QUOTE_ALL)"
      ],
      "metadata": {
        "id": "QRrUSPzn3y1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCfR5ZNM1bmy"
      },
      "outputs": [],
      "source": [
        "# dirty fix: нам нужен правильный токенизатор для multilingual модели\n",
        "import os\n",
        "\n",
        "broken_path = !python -c \"import os; import happytransformer; print(os.path.dirname(happytransformer.__file__))\"\n",
        "broken_path = str(list(broken_path)[0])\n",
        "\n",
        "fix_file = []\n",
        "with open(os.path.join(broken_path, \"happy_transformer.py\"), \"r\") as in_file:\n",
        "    for line in in_file.read().split(\"\\n\"):\n",
        "        if line == \"            self.tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token)\":\n",
        "            fix_file.append(\"            self.tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=use_auth_token, src_lang='ru_RU', tgt_lang='ru_RU')\")\n",
        "        else:\n",
        "            fix_file.append(line)\n",
        "with open(os.path.join(broken_path, \"happy_transformer.py\"), \"w\") as out_file:\n",
        "    out_file.write(\"\\n\".join(fix_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458,
          "referenced_widgets": [
            "f9629b6d016e48cdb9301e64ebc386f1",
            "ef796ea6071c4ed9915fa9482fab404b",
            "281fc411bc1041baaf880286c12ee5dd",
            "765759704d47445cbb4a9e0cafeffa5c",
            "4500ab2a5a674c2fad021e78c177cacc",
            "f3666e7b90344a3ba4177fdc895f2e1e",
            "a49cccfda4d449309fa4d54355434d21",
            "0e01d1020cc341828eebe765068f8721",
            "04a1aad5401d479887bbffe19ce9b32b",
            "8701ab22e9794c9f925ef2c1c4c4493e",
            "3700670cf71041b68400bd8819d8fed1",
            "341d636d424545d9bdd7229c73bcd8e3",
            "a1b48947cfa74d54b8e008fa9510dd4d",
            "c5bd24e7faed43c99848334980abb622",
            "24b48a0470894d138760fb2147648c9f",
            "6720f8ee36ca44c08b4edd739914a281",
            "348683df74364b82917990817bc263ec",
            "ab49aa2348cb417584cf9a5d36aa8534",
            "66a00b6473aa4e73875ce0154764b352",
            "da78b856e5d94d1b94c1a5fb80d2a282",
            "df8da4684b144a28845ae6de9d072877",
            "d394751f79944eebb329ef183d3a4f79",
            "13a2b1a693f1497886539560083d6829",
            "ba95f5fe7c354a948b527505f1f80061",
            "8132d0e73e664e5cae8a9f3a01ab9cf9",
            "dba95ab7950f49348653d9bfa7119647"
          ]
        },
        "id": "JHVbRMVw2wBU",
        "outputId": "10867b82-f24d-4710-dff6-971e074daab0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "03/20/2022 18:22:47 - INFO - happytransformer.happy_transformer -   Using model: cuda\n",
            "03/20/2022 18:22:49 - INFO - happytransformer.happy_transformer -   Preprocessing training data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-805d7d54be52421d/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13a2b1a693f1497886539560083d6829",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Downloading data files'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba95f5fe7c354a948b527505f1f80061",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value='Extracting data files'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-805d7d54be52421d/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8132d0e73e664e5cae8a9f3a01ab9cf9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dba95ab7950f49348653d9bfa7119647",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "03/20/2022 18:22:54 - INFO - happytransformer.happy_transformer -   Training...\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 12206\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 1\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 36618\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='36618' max='36618' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [36618/36618 1:50:21, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>5.651600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.454500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>2.974500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>3.002700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>2.569600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>2.093800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.945400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.824500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>1.760500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.759700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>1.721300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>1.620800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>1.749500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>1.721000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>1.663600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>1.583800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>1.559500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>1.632500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>1.536900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>1.526800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>1.493000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>1.555400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>1.506500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>1.536000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>1.254200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>1.046900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>1.010300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>1.061500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>1.041400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>1.040300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>1.028500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>1.108600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16500</td>\n",
              "      <td>1.044400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>0.981900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17500</td>\n",
              "      <td>1.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>1.013700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18500</td>\n",
              "      <td>1.028400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19000</td>\n",
              "      <td>1.014800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19500</td>\n",
              "      <td>1.021000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>1.028200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20500</td>\n",
              "      <td>1.028600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21000</td>\n",
              "      <td>0.994200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21500</td>\n",
              "      <td>0.986000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22000</td>\n",
              "      <td>0.993500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22500</td>\n",
              "      <td>0.929600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23000</td>\n",
              "      <td>0.966800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23500</td>\n",
              "      <td>1.011200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24000</td>\n",
              "      <td>1.009700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24500</td>\n",
              "      <td>0.897600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25000</td>\n",
              "      <td>0.550700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25500</td>\n",
              "      <td>0.594800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26000</td>\n",
              "      <td>0.533400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26500</td>\n",
              "      <td>0.550900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27000</td>\n",
              "      <td>0.589200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27500</td>\n",
              "      <td>0.510100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28000</td>\n",
              "      <td>0.548000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28500</td>\n",
              "      <td>0.574900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29000</td>\n",
              "      <td>0.562200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29500</td>\n",
              "      <td>0.545500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30000</td>\n",
              "      <td>0.585200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30500</td>\n",
              "      <td>0.550900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31000</td>\n",
              "      <td>0.555200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31500</td>\n",
              "      <td>0.579300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32000</td>\n",
              "      <td>0.585900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32500</td>\n",
              "      <td>0.544300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33000</td>\n",
              "      <td>0.555500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33500</td>\n",
              "      <td>0.531900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34000</td>\n",
              "      <td>0.497200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34500</td>\n",
              "      <td>0.540100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35000</td>\n",
              "      <td>0.520800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35500</td>\n",
              "      <td>0.563300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36000</td>\n",
              "      <td>0.537100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36500</td>\n",
              "      <td>0.591800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from happytransformer import HappyTextToText, TTTrainArgs\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# берём модель mBART от FB, размер чекпойнта large\n",
        "# cc25 содержит в себе меньше всего языков, что повышает точность модели\n",
        "model = HappyTextToText(\"BART\", \"facebook/mbart-large-cc25\")\n",
        "\n",
        "# 3 эпохи обучения\n",
        "args = TTTrainArgs(num_train_epochs=3) \n",
        "model.train(\"train.csv\", args=args)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate model"
      ],
      "metadata": {
        "id": "qsEA2myDyijH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4MYsrzA1bm0",
        "outputId": "76cde063-e71b-42ea-d365-17d749acd5c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[TextToTextResult(text='кто эту придумку придумывает.'),\n",
              " TextToTextResult(text='В такой в такой ситуации виноваты , из Ростелекома, у которых даже кошка может купить фильм с пульта'),\n",
              " TextToTextResult(text='актёр может и не плохой, но как человек - плохой'),\n",
              " TextToTextResult(text='мочите всех кто нарушает общественный порядок'),\n",
              " TextToTextResult(text='такие же люди и привели этих людей.'),\n",
              " TextToTextResult(text='А зачем тогда ты здесь это писал?.'),\n",
              " TextToTextResult(text='главный неудачник года уханя повар из полицейский из миннеаполиса сварщик из бейрута президент минска из d'),\n",
              " TextToTextResult(text='Начни со сваих людей..('),\n",
              " TextToTextResult(text='дайте уже пожить создать семью отдал 35 лет жизни кормил власти 30 лет мой отец 90 лет хватит'),\n",
              " TextToTextResult(text='а ты,что 41 год помнишь? сколько этой женщине денег заплатили,чтоб она такую чу несла.'),\n",
              " TextToTextResult(text='С которым через час расстанешься и будешь с другими общаться?'),\n",
              " TextToTextResult(text='Утые люди, зря, смотрят в зеркала'),\n",
              " TextToTextResult(text='Судья, бог накажет, все возвращается бумерангом'),\n",
              " TextToTextResult(text='Не отвечай на провокации этого человека всё и так ясно'),\n",
              " TextToTextResult(text='И как земля таких людей носит??'),\n",
              " TextToTextResult(text='да какое поколение, потеряли машину у тех кто войну проиграл.стыдно должно быть.'),\n",
              " TextToTextResult(text='О таких я даже не знаю,что писать!!!!'),\n",
              " TextToTextResult(text='Где они такие зарплаты нашли? ( зарплата'),\n",
              " TextToTextResult(text='Можно подумать, что хотят народу помочь. Все плохо во власть лезет, а этого просто кто то тащит в депутаты'),\n",
              " TextToTextResult(text='Проиграли не мы, а люди из правительства.')]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# подготавливаем тест сет\n",
        "test_df = pd.read_csv(\"./russe_detox_2022/data/input/test.tsv\", sep=\"\\t\")\n",
        "output = [model.generate_text(entry) for entry in tqdm(list(test_df[\"toxic_comment\"]))]\n",
        "output[:20]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сохраняем предсказания, подготавливаем для кодалаба\n",
        "with open(\"output_bart_large_3.txt\", \"w\") as out_file:\n",
        "    out_file.write(\"\\n\".join([entry.text for entry in output]))\n",
        "\n",
        "!zip output_bart_large_3.zip output_bart_large_3.txt"
      ],
      "metadata": {
        "id": "46YPmUmbDMcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export model"
      ],
      "metadata": {
        "id": "7abEmHk0yv8_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uvenuora1bm1",
        "outputId": "825fc9aa-d4d7-4209-fc5b-3817f1a0c4a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in bart_large_3/config.json\n",
            "Model weights saved in bart_large_3/pytorch_model.bin\n",
            "tokenizer config file saved in bart_large_3/tokenizer_config.json\n",
            "Special tokens file saved in bart_large_3/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "# сохраняем модель\n",
        "model.save(\"bart_large_3/\")\n",
        "!tar -czf bart_large_3.tar.gz bart_large_3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "QUQ5WDOQDdG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b30242ea-72e3-4579-dd59-f1ae294fcb0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# выгружаем веса на гугл диск\n",
        "\n",
        "#!mkdir /content/drive/MyDrive/rudetox\n",
        "!cp bart_large_3.tar.gz /content/drive/MyDrive/rudetox\n",
        "!cp output_bart_large_3.zip /content/drive/MyDrive/rudetox"
      ],
      "metadata": {
        "id": "xWoaNYKODgrN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}